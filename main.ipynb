{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-0eVRmw_Jlr",
        "outputId": "ab67e3e0-af2b-4d2d-f540-290721513b19"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "conn  = sqlite3.connect('merged_dataset_2.db')\n",
        "query = \"SELECT * FROM datasets_fixed\"\n",
        "df = pd.read_sql_query(query, conn)\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "nZEeJ9fQLR3s",
        "outputId": "f928bc83-8319-44ba-a3b0-a39b4121566f"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=['level_0', 'index'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eN6XdewpLtCw"
      },
      "outputs": [],
      "source": [
        "# import matplotlib\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# temp = '''\n",
        "# is_vpn\n",
        "# is_proxy\n",
        "# is_tor\n",
        "# is_relay\n",
        "# is_hosting\n",
        "# '''\n",
        "# temp = temp.replace('0', '')\n",
        "# temp = temp.split('\\n')\n",
        "\n",
        "# temp2 = []\n",
        "# for k in temp:\n",
        "#   if k != '':\n",
        "#     plt.figure()\n",
        "#     sns.countplot(x = k.strip(), hue='source', data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "O9o0hTwTNByY",
        "outputId": "e42b1666-83e6-4685-a1fc-40c05f045819"
      },
      "outputs": [],
      "source": [
        "df['is_hosting_filled'] = df['is_hosting'].fillna(0)\n",
        "df['is_hosting_filled'] = df['is_hosting_filled'].astype(int)\n",
        "df.drop(columns=['is_hosting'], inplace=True)\n",
        "df.rename(columns={'is_hosting_filled': 'is_hosting'}, inplace=True)\n",
        "\n",
        "df['formatted_output'] = df.apply(lambda row: f\"method: {row['method'].lower()}\\nheaders: {row['header_no_json']}\\nis_vpn:{'true' if row['is_vpn'] == 1 else 'false'}\\nis_proxy:{'true' if row['is_proxy'] == 1 else 'false'}\\nis_tor:{'true' if row['is_tor'] == 1 else 'false'}\\nis_relay:{'true' if row['is_relay'] == 1 else 'false'}\\nis_hosting:{'true' if row['is_hosting'] == 1 else 'false'}\\n\", axis=1)\n",
        "\n",
        "df.head()\n",
        "df.info()\n",
        "df['formatted_output'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "7G3TG9CrTiT7",
        "outputId": "d37553bf-a2f2-455a-920f-44554f4a5eb4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "conn  = sqlite3.connect('dataset_for_second_testing_2.db')\n",
        "query = \"SELECT * FROM dataset_for_second_testing_2\"\n",
        "df_validation = pd.read_sql_query(query, conn)\n",
        "conn.close()\n",
        "\n",
        "df_validation.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "p9qgzr3h_zP8",
        "outputId": "23a3abc8-0024-4459-cb86-31f526b92ee6"
      },
      "outputs": [],
      "source": [
        "df.value_counts(['source'])\n",
        "# df_validation.value_counts(['source'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYCM3hGpqkY2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "bots = df[df['source'] == 'bot']\n",
        "humans = df[df['source'] == 'human']\n",
        "\n",
        "bots_validation_split = bots.sample(n=200, random_state=42)\n",
        "humans_validation_split = humans.sample(n=200, random_state=42)\n",
        "\n",
        "df_validation_split = pd.concat([bots_validation_split, humans_validation_split])\n",
        "y_validation_split = pd.concat([bots_validation_split, humans_validation_split])\n",
        "y_validation_split = y_validation_split['source']\n",
        "\n",
        "df = df.drop(y_validation_split.index)\n",
        "y = df['source']\n",
        "\n",
        "df_validation_new = df_validation\n",
        "y_validation_new = df_validation['source']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izpSXbe-rrtn"
      },
      "outputs": [],
      "source": [
        "# df.head()\n",
        "# df.value_counts(['source'])\n",
        "# y\n",
        "\n",
        "# df_validation_split.head()\n",
        "# df_validation_split.value_counts(['source'])\n",
        "# y_validation_split\n",
        "\n",
        "# df_validation_new.head()\n",
        "# df_validation_new.value_counts(['source'])\n",
        "# y_validation_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi1CLBsg6hul",
        "outputId": "1e07ccbe-4b27-4eff-d6df-1ecef1cf0105"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tabulate import tabulate\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import zipfile\n",
        "import glob\n",
        "\n",
        "plt.rcParams.update({\n",
        "    'font.size': 24,           # Base font size\n",
        "    'axes.titlesize': 14,      # Title font size\n",
        "    'axes.labelsize': 14,      # Axis label font size\n",
        "    'xtick.labelsize': 12,     # X tick labels\n",
        "    'ytick.labelsize': 12      # Y tick labels\n",
        "})\n",
        "\n",
        "\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
        "    \"Linear SVC\": LinearSVC(random_state=42),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Multinomial Naive Bayes\": MultinomialNB(),\n",
        "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
        "    \"MLP Classifier\": MLPClassifier(random_state=42, max_iter=1000),\n",
        "}\n",
        "\n",
        "def evaluate_model_graph(\n",
        "    X_text_vec,\n",
        "    y,\n",
        "    X_text_vec2,\n",
        "    y_test_test1,\n",
        "    X_text_vec3,\n",
        "    y_test_test2,\n",
        "    models,\n",
        "    vectorizer_name\n",
        "):\n",
        "    print(f\"Vectorizer: {vectorizer_name}\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_text_vec, y, test_size=0.75, random_state=42)\n",
        "\n",
        "    table_data = []\n",
        "\n",
        "    for name, model in models.items():\n",
        "        # Train\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred_train = model.predict(X_train)\n",
        "        train_accuracy = model.score(X_train, y_train)\n",
        "        train_f1_weighted = classification_report(y_train, y_pred_train, output_dict=True)['weighted avg']['f1-score']\n",
        "\n",
        "        # Validation\n",
        "        y_pred_val = model.predict(X_test)\n",
        "        val_accuracy = model.score(X_test, y_test)\n",
        "        val_f1_weighted = classification_report(y_test, y_pred_val, output_dict=True)['weighted avg']['f1-score']\n",
        "\n",
        "        # Test1\n",
        "        y_pred_test1 = model.predict(X_text_vec2)\n",
        "        test1_accuracy = model.score(X_text_vec2, y_test_test1)\n",
        "        test1_f1_weighted = classification_report(y_test_test1, y_pred_test1, output_dict=True)['weighted avg']['f1-score']\n",
        "\n",
        "        # Test2\n",
        "        y_pred_test2 = model.predict(X_text_vec3)\n",
        "        test2_accuracy = model.score(X_text_vec3, y_test_test2)\n",
        "        test2_f1_weighted = classification_report(y_test_test2, y_pred_test2, output_dict=True)['weighted avg']['f1-score']\n",
        "\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
        "        ConfusionMatrixDisplay.from_predictions(y_train, y_pred_train, ax=axes[0, 0], cmap='Blues')\n",
        "        axes[0, 0].set_title(f'{name} - Train')\n",
        "        ConfusionMatrixDisplay.from_predictions(y_test, y_pred_val, ax=axes[0, 1], cmap='Blues')\n",
        "        axes[0, 1].set_title(f'{name} - Validation')\n",
        "        ConfusionMatrixDisplay.from_predictions(y_test_test1, y_pred_test1, ax=axes[1, 0], cmap='Blues')\n",
        "        axes[1, 0].set_title(f'{name} - Test 1')\n",
        "        ConfusionMatrixDisplay.from_predictions(y_test_test2, y_pred_test2, ax=axes[1, 1], cmap='Blues')\n",
        "        axes[1, 1].set_title(f'{name} - Test 2')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'confusion_{name.replace(\" \", \"_\").lower()}.png')\n",
        "        plt.close(fig)\n",
        "\n",
        "        table_data.append([\n",
        "            name,\n",
        "            f\"{train_accuracy * 100:.2f}%\",\n",
        "            f\"{train_f1_weighted * 100:.2f}%\",\n",
        "            f\"{val_accuracy * 100:.2f}%\",\n",
        "            f\"{val_f1_weighted * 100:.2f}%\",\n",
        "            f\"{test1_accuracy * 100:.2f}%\",\n",
        "            f\"{test1_f1_weighted * 100:.2f}%\",\n",
        "            f\"{test2_accuracy * 100:.2f}%\",\n",
        "            f\"{test2_f1_weighted * 100:.2f}%\"\n",
        "        ])\n",
        "\n",
        "    headers = [\n",
        "        \"Model\",\n",
        "        \"Train Acc\", \"Train F1\",\n",
        "        \"Val Acc\", \"Val F1\",\n",
        "        \"Test1 Acc\", \"Test1 F1\",\n",
        "        \"Test2 Acc\", \"Test2 F1\"\n",
        "    ]\n",
        "\n",
        "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
        "\n",
        "    image_files = glob.glob(\"confusion_*.png\")\n",
        "\n",
        "    with zipfile.ZipFile(\"confusion_matrices.zip\", \"w\") as zipf:\n",
        "        for img in image_files:\n",
        "            zipf.write(img)\n",
        "    print(\"All confusion matrix images have been zipped into confusion_matrices.zip\")\n",
        "\n",
        "\n",
        "vectorizer_count = CountVectorizer(min_df=0.05, max_df=0.15, ngram_range=(2, 2), lowercase=False)\n",
        "X_text_vec = vectorizer_count.fit_transform(df['formatted_output']).toarray()\n",
        "X_text_vec2 = vectorizer_count.transform(df_validation_split['formatted_output']).toarray()\n",
        "X_text_vec3 = vectorizer_count.transform(df_validation_new['formatted_output']).toarray()\n",
        "\n",
        "evaluate_model_graph(X_text_vec, y, X_text_vec2, y_validation_split, X_text_vec3, y_validation_new, models, \"Count Vectorizer\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
